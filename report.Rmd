---
title: 'A Bayesian approach to analyzing urinary biomarkers for pancreatic cancer'
author: "Noora Torpo, Joel Himanen"
date: "11/25/2021"
output: pdf_document
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

1)  Introduction describing the motivation, the problem and the main modeling idea. Showing some illustrative figure is recommended. (J)
2)  Description of the data and the analysis problem. Provide information where the data was obtained, and if it has been previously used in some online case study and how your analysis differs from the existing analyses. (J)
3)  Description of at least two models, for example: non hierarchical and hierarchical, linear and non linear, variable selection with many models. Pooled (J); Hierarchical (N)
4)  Informative or weakly informative priors, and justification of their choices. (N)
5)  Stan, rstanarm or brms code.
6)  How the Stan model was run, that is, what options were used. This is also more clear as combination of textual explanation and the actual code line. (J)
7)  Convergence diagnostics (Rˆ, ESS, divergences) and what was done if the convergence was not good with the first try. (J)
8)  Posterior predictive checks and what was done to improve the model. (N)
9)  Model comparison (e.g. with LOO-CV). (J)
10) Predictive performance assessment if applicable (e.g. classification accuracy) and evaluation of practical usefulness of the accuracy. If not applicable, then explanation why in this case the predictive performance is not applicable. (N)
11) Sensitivity analysis with respect to prior choices (i.e. checking whether the result changes a lot if prior is changed) (N)
12) Discussion of issues and potential improvements.
13) Conclusion what was learned from the data analysis.
14) Self-reflection of what the group learned while making the project.

# 1 Introduction

Pancreatic cancer, or more accurately, its most common form, *Pancreatic ductal adenocarcinoma* (PDAC), is one of the most lethal forms of cancer.
It is often diagnosed at a very late stage, which, combined to its heterogenous base of genetic mutations, leads to an average 5-year survival rate of less than 10%.[1] Therefore, research on early signs of PDAC can be considered to be of utmost importance.

This study focuses on conducting Bayesian inference on a data set, which holds measurements of potential biomarkers for PDAC.
We aim to model the biomarker levels using weakly informative priors to generate posterior distributions using two different approaches in Stan and R.
The goal is to see if and how the distributions for the different biomarkers differ between healthy and positively diagnosed test subjects.

# 2 Data & workflow

The data used in this study dates back to research done by Debernardi et al. in 20020.[2] The set includes information and measurements from 590 test subjects, the measurements considered in this study being amounts of four different proteins measured from urine samples:

-   **Creatinine**, commonly used to indicate kidney function
-   **LYVE1** (lymphatic vessel endothelial hyaluronan receptor 1), may have a part in tumor metastasis
-   **REG1B**, potentially related to pancreas regeneration
-   **TFF1** (trefoil factor 1), may be associated with regeneration and repair of the urinary tract

Of these, the three latter ones are considered target biomarkers, that could potentially help early diagnosis of PDAC.

Test subjects are divided into three different groups:

-   1 = Healthy control subjects (183 samples)
-   2 = Subjects with some beningn pancreatic disease (208 samples)
-   3 = Subjects with a positive PDAC diagnosis (199 samples)

Figure 1 is a visualization of these observations. Each histogram represents one of the four measured protein amounts. The subject groups are color coded (1 = green, 2 = blue, 3 = red), with overlaps presented as mixtures of the overlapping colors.  

```{r, echo=FALSE, out.width="60%", out.height="30%", fig.cap="Histograms of the observed data", fig.show='hold', fig.align='center'}
knitr::include_graphics(c('./images/creatinine_data.png','./images/lyve1_data.png', './images/reg1b_data.png', './images/tff1_data.png'))
``` 

The workflow of this study attempts to fit some probability distributions to each of the four protein levels in all three subject groups.
This is done by choosing non- or weakly informative priors for the parameters of these target distributions.
Using Stan, we then compute the likelihoods for our observations, and generate the resulting posterior distributions.
Our hypothesis is, that the posterior distributions of at least some of the biomarkers differ considerably between healthy and PDAC-positive groups.
We will also compare two different modeling approaches:

-   A pooled model, where we assume all three subject groups have the same prior distributions
-   A hierarchical model, where each prior has differently distributed hyperparameters

Data analysis in the original paper was done using "classical" statistical learning theory and tests.
To our knowledge, no other analyses have been performed on this dataset, so we can assume that this is the first time a Bayesian approach has been used on this case.

# 3 Models

In this problem setting, we are fitting two types of models for the data: a pooled model and a hierarchical model. The goal is to find distributions for proteins for all three diagnosis groups. Therefore, the input data includes three matrices including the data as well as the number of observations. Note that the groups have different lengths. The data is denoted by $y_i$, $i=1,2,3$ corresponding to each group, where each column of presents four different proteins. Similarly the number of observations is denote as $n_i$. For the pooled model, we are using same parameters for all of the groups meaning that we are note considering the groups but the whole data set. For hierarchical model, the distributions have shared hyperparameters but for different groups, the distributions are fitted separately. 

As mentioned above, we are considering four proteins or biomarkers: creatinine, LYVE1, REG1B and TFF1. In both pooled and hierarchical model, the distributions are fitted separately for each protein. After considering the distributions of the data, we decided to fit an exponential model with two parameters to creatinine and after logarithmic transformation we decided to fit a Gaussian model to the three remaining proteins. In practice, this means that we are fitting gamma distribution, as we are using mathematically more general formulation of exponential model, to creatinine data and normal distribution to log-transformed data of LYVE1, REG1B and TFF1. Note that we are using natural logarithm. After logarithmic transformation, the histograms of the three proteins were similar enough for us to use same prior distributions for their parameters. The decision on on the usage of the log-scale and normal distribution was made after it turned out that the exponential model could not be fitted to the data sensibly.

TÄHÄN LISÄTÄÄN VIELÄ PAREMMAT PERUSTELUT EKSPONENTIALISEN JA NORMAALIMALLIN VALINNASTA, KUN TIETÄÄ MITÄ KAKKOS KOHTAAN ON KIRJOITETTU DATASTA JA MIHIN KUVIIN VAIKKA VIITATA.

## Pooled model

Exponential model fitted to the creatinine data can be written as follows. Note that the choice of priors will be discussed in part 4. The first column of the data is denoted as $y_i^1$. Gamma distribution is denoted as $\Gamma$.

$$
\begin{aligned}
y_i^1 &\sim \Gamma(\alpha, \beta) \hspace{1cm} i=1,2,3 \\
\alpha &\sim \Gamma(1,1) \\
\beta &\sim \Gamma(0.5,1)
\end{aligned}
$$

The Gaussian model fitted to the data for three other proteins can be written as follows. Indexing $j=2,3,4$ refers to the proteins LYVE1, REB1B and TFF1 respectively.

$$
\begin{aligned}
ln(y_i^j) &\sim \mathcal{N}\left(\mu^j, {\sigma^j}^2\right) \hspace{1cm} i=1,2,3 \hspace{5mm} j=2,3,4 \\
\mu^j &\sim \mathcal{N}\left(0,20^2\right)  \\
\sigma^j &\sim \Gamma(1,1)  \\
\end{aligned}
$$

## Hierarchical model

Hierarchical model is constricted similarly but defined priors use hyperparametrs. In general, we will denote hyperparameters with lower index P. The corresponding hierarchical formulation of the exponential model to the creatinine data can be written as follows.


$$
\begin{aligned}
y_i^1 &\sim \Gamma(\alpha_i, \beta_i) \hspace{1cm} i=1,2,3 \\
\alpha_i &\sim \Gamma(\alpha_{P_1},\beta_{P_1}) \\
\beta_i &\sim \Gamma(\alpha_{P_1},\beta_{P_1}) \\
\alpha_{P_k} &\sim \Gamma(1,1) \hspace{1cm} k=1,2 \\
\beta_{P_k} &\sim \Gamma(1,1)
\end{aligned}
$$
The corresponding hierarchical formulation of the Gaussian model fitted to the data for three other proteins can be written as follows.

$$
\begin{aligned}
ln(y_i^j) &\sim \mathcal{N}\left(\mu^j_i, {\sigma^j_i}^2\right) \hspace{1cm} &i=1,2,3 \hspace{5mm} j=2,3,4 \\
\mu^j_i &\sim \mathcal{N}\left(\mu_{P_1}^j,{\sigma_{P_1}^j}^2\right)   \\
\sigma^j_i &\sim \Gamma\left(\mu_{P_2}^j,\sigma_{P_2}^j\right) \\
\mu_{P_1}^j &\sim \mathcal{N}\left(0,20^2\right) \\
\mu_{P_2}^j &\sim \Gamma(1,1) \\
\sigma_{P_k}^j &\sim \Gamma(1,1) & k=1,2
\end{aligned}
$$

# 4 Priors

In general, the models required two kind of prior distributions. For parameters of gamma distribution, it is essentials to keep them positive which narrows the possible choice of priors. As presented in the course books Bayesian Data Analysis, gamma distribution is a conjugate prior for exponential model. Therefore, gamma distribution was natural choice for prior distributions for both parameters $\alpha$ and $\beta$ for creatinine. The gamma distribution is easily quite narrow so we decided to consider informative priors but aim for enough flexibility in the model. 

The first parameter of gamma distribution $\alpha$ determines the shape of the distribution and the second parameter $\beta$ the scale. After considering creatinine data, we decided to roughly aim for expected value of 1 for the shape and expected value of 0.5 for the scale parameter. The expected value of gamma distribution is calculated as $\frac{\alpha}{\beta}$ so possible prior distributions would be $\Gamma(1,1)$ and $\Gamma(0.5,1)$. For gamma distribution, small values for the parametrs work well since the shape stays non specific. The distributions are plotted below.

```{r, echo=FALSE, out.width="60%", out.height="30%", fig.cap="Histograms of the observed data", fig.show='hold', fig.align='center'}
knitr::include_graphics(c('./images/gamma_priors.png'))
``` 

For other three proteins, we are fitting Gaussian model. It is important to note that we are fitting similar model to each of the protein LYVE1, REG1B and TFF1 but they are not connected to each other. We need a prior distributions for the mean value and for the standard deviation. The prior of the mean is chosen so that it is sensible but not restricting. In part 2, we have seen that the values of all three proteins after logarithmic transformation, obtain both negative and positive values. This is why we will choose the mean of the prior of the parameter $\mu$ as 0. To be able to easily adjust to the data we will chose large value for the standard deviation as 20. Hence the prior distribution for the mean is $\mathcal{N}(0,20)$. In sensitivity analysis, we will notice that the choice of the standard deviation does not affect the result strongly as long as it is wide enough. The prior distribution for $\sigma$ is chosen as $\Gamma(1,1)$ so that it stays positive and gives wide enough range of values.

For hierarchical model, we need to define prior distributions for the hyperparameters. Here we use same logic as above and choose prior distributions for all the hyperparameters that are required to be positive as $\Gamma(1,1)$ and hyperparameter of the mean of the normal distribution as \mathcal{N}(0,20)$. These priors provide enough flexibility because as hyperprior the resulting distributions for the group specific parameters can differ more. 

# N Fitting the models

Both of the models were first run with the default options of the `rstan::stan()` function, that is

- Number of chains: 4
- Chain length: 2000
- Warmup length: floor(chain length / 2)

The pooled model seemed to converge excellently with the default options. There were no divergences and all $\hat{R}$ values differed from 1 by no more than roughly $10^{-2}$, so there was no need to tweak the options in this case.

The fitting of the hierarchical model raised a warning that we had a bit over 200 divergent post-warmup transitions. Our first attempt to get that number down was to double the chain length, which seemed to have at least some positive effect. Then we lowered the sampling step size by setting the `adapt_delta` parameter to 0.99. This had a very good effect, and we were able to get the number of divergences to under 20. At this point, we decided to accept the result. Below is an example code block, showing how the hierarchical model was run.

```{r, eval=FALSE}
hier_fit <- stan(
  file = 'path/to/repository/cancer-biomarker-analysis/models/hierarchical.stan',
  data = stan_data,
  iter = 4000,
  control = list(adapt_delta = 0.99)
)
```


# References

-   [1] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7031151/
-   [2] Debernardi S, O'Brien H, Algahmdi AS, Malats N, Stewart GD, Plješa-Ercegovac M, et al. (2020) *A combination of urinary biomarker panel and PancRISK score for earlier detection of pancreatic cancer: A case--control study.* PLoS Med 17(12): e1003489. https://doi.org/10.1371/journal.pmed.1003489
