---
title: 'A Bayesian approach to analyzing urinary biomarkers for pancreatic cancer'
author: "Noora Torpo, Joel Himanen"
date: "11/25/2021"
output: pdf_document
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

1)  Introduction describing the motivation, the problem and the main modeling idea. Showing some illustrative figure is recommended. (J)
2)  Description of the data and the analysis problem. Provide information where the data was obtained, and if it has been previously used in some online case study and how your analysis differs from the existing analyses. (J)
3)  Description of at least two models, for example: non hierarchical and hierarchical, linear and non linear, variable selection with many models. Pooled (J); Hierarchical (N)
4)  Informative or weakly informative priors, and justification of their choices. (N)
5)  Stan, rstanarm or brms code.
6)  How the Stan model was run, that is, what options were used. This is also more clear as combination of textual explanation and the actual code line. (J)
7)  Convergence diagnostics (Rˆ, ESS, divergences) and what was done if the convergence was not good with the first try. (J)
8)  Posterior predictive checks and what was done to improve the model. (N)
9)  Model comparison (e.g. with LOO-CV). (J)
10) Predictive performance assessment if applicable (e.g. classification accuracy) and evaluation of practical usefulness of the accuracy. If not applicable, then explanation why in this case the predictive performance is not applicable. (N)
11) Sensitivity analysis with respect to prior choices (i.e. checking whether the result changes a lot if prior is changed) (N)
12) Discussion of issues and potential improvements.
13) Conclusion what was learned from the data analysis.
14) Self-reflection of what the group learned while making the project.

# 1 Introduction

Pancreatic cancer, or more accurately, its most common form, *Pancreatic ductal adenocarcinoma* (PDAC), is one of the most lethal forms of cancer.
It is often diagnosed at a very late stage, which, combined to its heterogenous base of genetic mutations, leads to an average 5-year survival rate of less than 10%.[1] Therefore, research on early signs of PDAC can be considered to be of utmost importance.

This study focuses on conducting Bayesian inference on a data set, which holds measurements of potential biomarkers for PDAC.
We aim to model the biomarker levels using weakly informative priors to generate posterior distributions using two different approaches in Stan and R.
The goal is to see if and how the distributions for the different biomarkers differ between healthy and positively diagnosed test subjects.

# 2 Data & workflow

The data used in this study dates back to research done by Debernardi et al. in 20020.[2] The set includes information and measurements from 590 test subjects, the measurements considered in this study being amounts of four different proteins measured from urine samples:

-   **Creatinine**, commonly used to indicate kidney function
-   **LYVE1** (lymphatic vessel endothelial hyaluronan receptor 1), may have a part in tumor metastasis
-   **REG1B**, potentially related to pancreas regeneration
-   **TFF1** (trefoil factor 1), may be associated with regeneration and repair of the urinary tract

Of these, the three latter ones are considered target biomarkers, that could potentially help early diagnosis of PDAC.

Test subjects are divided into three different groups:

-   1 = Healthy control subjects (183 samples)
-   2 = Subjects with some beningn pancreatic disease (208 samples)
-   3 = Subjects with a positive PDAC diagnosis (199 samples)

Figure 1 is a visualization of these observations. Each histogram represents one of the four measured protein amounts. The subject groups are color coded (1 = green, 2 = blue, 3 = red), with overlaps presented as mixtures of the overlapping colors.  

```{r, echo=FALSE, out.width="60%", out.height="30%", fig.cap="Histograms of the observed data", fig.show='hold', fig.align='center'}
knitr::include_graphics(c('./images/creatinine_data.png','./images/lyve1_data.png', './images/reg1b_data.png', './images/tff1_data.png'))
``` 

The workflow of this study attempts to fit some probability distributions to each of the four protein levels in all three subject groups.
This is done by choosing non- or weakly informative priors for the parameters of these target distributions.
Using Stan, we then compute the likelihoods for our observations, and generate the resulting posterior distributions.
Our hypothesis is, that the posterior distributions of at least some of the biomarkers differ considerably between healthy and PDAC-positive groups.
We will also compare two different modeling approaches:

-   A pooled model, where we assume all three subject groups have the same prior distributions
-   A hierarchical model, where each prior has differently distributed hyperparameters

Data analysis in the original paper was done using "classical" statistical learning theory and tests.
To our knowledge, no other analyses have been performed on this dataset, so we can assume that this is the first time a Bayesian approach has been used on this case.

# 3 Models

In this problem setting, we are fitting two types of models for the data: a pooled model and a hierarchical model. The goal is to find distributions for proteins for all three diagnosis groups. Therefore, the input data includes three matrices including the data as well as the number of observations. Note that the groups have different lengths. The data is denoted by $y_i$, $i=1,2,3$ corresponding to each group, where each column of presents four different proteins. Similarly the number of observations is denote as $n_i$. For the pooled model, we are using same parameters for all of the groups meaning that we are note considering the groups but the whole data set. For hierarchical model, the distributions have shared hyperparameters but for different groups, the distributions are fitted separately. 

As mentioned above, we are considering four proteins or biomarkers: creatinine, LYVE1, REG1B and TFF1. In both pooled and hierarchical model, the distributions are fitted separately for each protein. After considering the distributions of the data, we decided to fit an exponential model with two parameters to creatinine and after logarithmic transformation we decided to fit a Gaussian model to the three remaining proteins. In practice, this means that we are fitting gamma distribution, as we are using mathematically more general formulation of exponential model, to creatinine data and normal distribution to log-transformed data of LYVE1, REG1B and TFF1. Note that we are using natural logarithm. After logarithmic transformation, the histograms of the three proteins were similar enough for us to use same prior distributions for their parameters. The decision on on the usage of the log-scale and normal distribution was made after it turned out that the exponential model could not be fitted to the data sensibly.

TÄHÄN LISÄTÄÄN VIELÄ PAREMMAT PERUSTELUT EKSPONENTIALISEN JA NORMAALIMALLIN VALINNASTA, KUN TIETÄÄ MITÄ KAKKOS KOHTAAN ON KIRJOITETTU DATASTA JA MIHIN KUVIIN VAIKKA VIITATA.

## Pooled model

Exponential model fitted to the creatinine data can be written as follows. Note that the choice of priors will be discussed in part 4. The first column of the data is denoted as $y_i^1$. Gamma distribution is denoted as $\Gamma$.

$$
\begin{aligned}
y_i^1 &\sim \Gamma(\alpha, \beta) \hspace{1cm} i=1,2,3 \\
\alpha &\sim \Gamma(1,1) \\
\beta &\sim \Gamma(0.5,1)
\end{aligned}
$$

The Gaussian model fitted to the data for three other proteins can be written as follows. Indexing $j=2,3,4$ refers to the proteins LYVE1, REB1B and TFF1 respectively.

$$
\begin{aligned}
ln(y_i^j) &\sim \mathcal{N}\left(\mu^j, {\sigma^j}^2\right) \hspace{1cm} i=1,2,3 \hspace{5mm} j=2,3,4 \\
\mu^j &\sim \mathcal{N}\left(0,20^2\right)  \\
\sigma^j &\sim \Gamma(1,1)  \\
\end{aligned}
$$

## Hierarchical model

Hierarchical model is constricted similarly but defined priors use hyperparametrs. In general, we will denote hyperparameters with lower index P. The corresponding hierarchical formulation of the exponential model to the creatinine data can be written as follows.


$$
\begin{aligned}
y_i^1 &\sim \Gamma(\alpha_i, \beta_i) \hspace{1cm} i=1,2,3 \\
\alpha_i &\sim \Gamma(\alpha_{P_1},\beta_{P_1}) \\
\beta_i &\sim \Gamma(\alpha_{P_1},\beta_{P_1}) \\
\alpha_{P_k} &\sim \Gamma(1,1) \hspace{1cm} k=1,2 \\
\beta_{P_k} &\sim \Gamma(1,1)
\end{aligned}
$$
The corresponding hierarchical formulation of the Gaussian model fitted to the data for three other proteins can be written as follows.

$$
\begin{aligned}
ln(y_i^j) &\sim \mathcal{N}\left(\mu^j_i, {\sigma^j_i}^2\right) \hspace{1cm} &i=1,2,3 \hspace{5mm} j=2,3,4 \\
\mu^j_i &\sim \mathcal{N}\left(\mu_{P_1}^j,{\sigma_{P_1}^j}^2\right)   \\
\sigma^j_i &\sim \Gamma\left(\mu_{P_2}^j,\sigma_{P_2}^j\right) \\
\mu_{P_1}^j &\sim \mathcal{N}\left(0,20^2\right) \\
\mu_{P_2}^j &\sim \Gamma(1,1) \\
\sigma_{P_k}^j &\sim \Gamma(1,1) & k=1,2
\end{aligned}
$$

# 4 Priors

In general, the models required two kind of prior distributions. For parameters of gamma distribution, it is essentials to keep them positive which narrows the possible choice of priors. As presented in the course books Bayesian Data Analysis, gamma distribution is a conjugate prior for exponential model. Therefore, gamma distribution was natural choice for prior distributions for both parameters $\alpha$ and $\beta$ for creatinine. The gamma distribution is easily quite narrow so we decided to consider informative priors but aim for enough flexibility in the model. 

The first parameter of gamma distribution $\alpha$ determines the shape of the distribution and the second parameter $\beta$ the scale. After considering creatinine data, we decided to roughly aim for expected value of 1 for the shape and expected value of 0.5 for the scale parameter. The expected value of gamma distribution is calculated as $\frac{\alpha}{\beta}$ so possible prior distributions would be $\Gamma(1,1)$ and $\Gamma(0.5,1)$. For gamma distribution, small values for the parameters work well since the shape stays non specific. The distributions are plotted below.

```{r, echo=FALSE, out.width="60%", out.height="30%", fig.cap="Piror distributions", fig.show='hold', fig.align='center'}
knitr::include_graphics(c('./images/gamma_priors.png'))
``` 

For other three proteins, we are fitting Gaussian model. It is important to note that we are fitting similar model to each of the protein LYVE1, REG1B and TFF1 but they are not connected to each other. We need a prior distributions for the mean value and for the standard deviation. The prior of the mean is chosen so that it is sensible but not restricting. In part 2, we have seen that the values of all three proteins after logarithmic transformation, obtain both negative and positive values. This is why we will choose the mean of the prior of the parameter $\mu$ as 0. To be able to easily adjust to the data we will chose large value for the standard deviation as 20. Hence the prior distribution for the mean is $\mathcal{N}(0,20)$. In sensitivity analysis, we will notice that the choice of the standard deviation does not affect the result strongly as long as it is wide enough. The prior distribution for $\sigma$ is chosen as $\Gamma(1,1)$ so that it stays positive and gives wide enough range of values.

For hierarchical model, we need to define prior distributions for the hyperparameters. Here we use same logic as above and choose prior distributions for all the hyperparameters that are required to be positive as $\Gamma(1,1)$ and hyperparameter of the mean of the normal distribution as $\mathcal{N}(0,20)$. These priors provide enough flexibility because as hyperprior the resulting distributions for the group specific parameters can differ more. 

# 5 Stan code

# 6 Fitting the models

Both of the models were first run with the default options of the `rstan::stan()` function, that is

- Number of chains: 4
- Chain length: 2000
- Warmup length: floor(chain length / 2)

The pooled model seemed to converge excellently with the default options. There were no divergences and all $\hat{R}$ values differed from 1 by no more than roughly $10^{-2}$, so there was no need to tweak the options in this case.

The fitting of the hierarchical model raised a warning that we had a bit over 200 divergent post-warmup transitions. Our first attempt to get that number down was to double the chain length, which seemed to have at least some positive effect. Then we lowered the sampling step size by setting the `adapt_delta` parameter to 0.99. This had a very good effect, and we were able to get the number of divergences to under 20. At this point, we decided to accept the result. Below is an example code block, showing how the hierarchical model was run.

```{r, eval=FALSE}
hier_fit <- stan(
  file = 'path/to/repository/cancer-biomarker-analysis/models/hierarchical.stan',
  data = stan_data,
  iter = 4000,
  control = list(adapt_delta = 0.99)
)
```

# 7 Convergence diagnostics

# 8 Posterior predictive checks

Posterior predictive checks were completed visually in this project. The stan models include generation of predictive samples for each diagnosis group and protein. In general the posterior predictive check was done as follows. For both models, the same number of samples as in the original dataset was drawn four times. This samples were plotted as a histogram so that the distribution can be compared to the original histogram. Below you can find the figures. The original data is plotted as white histogram on the background and coloured histograms present the draws.

## Pooled model

For the pooled model, we are using same parameters for each diagnosis group. Therefore, it is relevant to look at the data of each protein as one entity. 

```{r, echo=FALSE, out.width="40%", out.height="20%", fig.cap="Posterior predictive checks for the pooled model", fig.show='hold', fig.align='center'}
knitr::include_graphics(c('./images/post_check_pooled_creatinine.png','./images/post_check_pooled_LYVE1.png', './images/post_check_pooled_REG1B.png', './images/post_check_pooled_TFF1.png'))
``` 

We can see that for creatinine and REG1B replicated samples correspond to the original data quite well. For REG1B, the normal distribution cannot present the longer tail on the left that the actual data has. However, the overall fit is satisfying. LYVE1 and TFF1 cause more reason to worry since the original data, after log-transformation, has two spikes meaning the actual distribution would be multi-modal. The normal distribution does not replicate well compared to the data because it is rather a compromize between these two peaks. However, pooled model is already a combination of all of the diagnosis groups so it could be expected that the fits to the data are not as good.

## Hierarchical model

For hierarchical model we obtain overall of twelve figures that are presented below grouped by the diagnosis group. Similarly as in the pooled model replicated data sets for creatinine and REG1B correspond quite well to the original data for each diagnosis group. The same issue for REG1B can be seen here as the skewness of the data cannot be taken into account with normal distribution. This is a clear improvement point but especially for diagnosis group 3 the fit is actually quite good and covers all the extreme values.

For LYVE2 and TFF1 the same issue with two spikes in the data can still be seen, especially with diagnosis group 1 and 2. It is interesting to see that in diagnosis group 1 with healthy control group there is two clear peaks in the data. It would be a good issue to investigate more closely. On the other hand, the fit in diagnosis group 1 is maybe even better than in diagnosis group 2 since there the skewness of multi-model distribution makes the normal distribution very bad choice since it needs to be wide. For protein LYVE1 and diagnosis group 3, the fit is actually quite good even though there are some extreme values on the left that normal distribution cannot replicate. For TFF1, the issues are very similar but the other spike is not as large so the issues are not as strong. In general, the replicate data is better but there is still definitely room for improvement. It might be a good idea to fit multi-modal distribution insetad of normal distribution.

```{r, echo=FALSE, out.width="40%", out.height="20%", fig.cap="Posterior predictive checks for diagnonsis 1 and the hierarchical model", fig.show='hold', fig.align='center'}
knitr::include_graphics(c('./images/post_check_hier_creatinine_1.png','./images/post_check_hier_LYVE1_1.png', './images/post_check_hier_REG1B_1.png', './images/post_check_hier_TFF1_1.png'))
``` 

```{r, echo=FALSE, out.width="40%", out.height="20%", fig.cap="Posterior predictive checks for diagnonsis 2 and the hierarchical model", fig.show='hold', fig.align='center'}
knitr::include_graphics(c('./images/post_check_hier_creatinine_2.png','./images/post_check_hier_LYVE1_2.png', './images/post_check_hier_REG1B_2.png', './images/post_check_hier_TFF1_2.png'))
``` 

```{r, echo=FALSE, out.width="40%", out.height="20%", fig.cap="Posterior predictive checks for diagnonsis 3 and the hierarchical model", fig.show='hold', fig.align='center'}
knitr::include_graphics(c('./images/post_check_hier_creatinine_3.png','./images/post_check_hier_LYVE1_3.png', './images/post_check_hier_REG1B_3.png', './images/post_check_hier_TFF1_3.png'))
``` 

# 9 Model comaprison

# 10 Predictive performance assessment

This model is not applicable for predictive assessment since it does not use predictors but rather describes the distributions and their differences. Only predictive aspect of the model might be predicting the protein levels of a person based on their diagnosis. But since we are not using any other predictors at this point, it is not relevant or interesting. The results of this model could be used to create a predictive model where the biomarkers are used to predict occurrence of the cancer. These results could guide on how the predictive model could be build and what kind of dependence there are between the cancer and the biomarkers.

# 11 Sensitivity analysis

Sensitivity analysis was carried out by comparing six different scenarios of priors for both models. In both cases, the different resulting posterior distributions were plotted and values of stan monitor checked. Sensitivity analysis was restricted to varying the parameters of the chosen prior distributions.

## Pooled model

For pooled model, the used scenarios are presented below in a table. In the first three scenarios, parameters values are varied only a little. The last three scenarios are extreme cases were the values have been changed drastically. 

By looking at the figures we can see that only the scenarios with very large variation in the prior parameters differ seemingly from each other. For all the protein, only scenarios 5 and 6 are separate from other results. For creatinine, the changes are visible but not great. For other three proteins, only scenario 6 really fails to create similar posterior distribution. The reason for this is in the prior o the mean value of the normal distribution and we an safely say that $\mathcal{N}(-1000,1)$ is very unrealistic option. Overall, we can conclude that the model is very robust and not sensitive when varying the parameters of the prior distributions. In addition, the pooled model was fitted smoothly with all of the prior choices which was not the case with the hierarchical model as can be seen below.

```{r echo = FALSE, results = 'asis'}
library(knitr)
S <- matrix(c(1,1,0.5,1,0,20,1,1,
             2,2,1,2,0,10,2,2,
             0.5,0.5,0.1,0.5,0,2,0.5,0.5,
             0.01,0.01,0.01,0.01,10,1,0.01,0.01,
             100,100,100,100,1000,1000,100,100,
             100,0.01,100,0.01,-1000,1,100,0.01), ncol = 8, byrow = T)
df <- data.frame(S)
rownames(df) <- c('Scenario 1','Scenario 2','Scenario 3','Scenario 4','Scenario 5','Scenario 6')
colnames(df) <- c('Shape of alpha', 'Scale of alpha','Shape of beta', 'Scale of beta',
                  'Mean of mu^j', 'Deviation of mu^j','Shape of sigma^j', 'Scale of sigma^j')
kable(df, caption='Scenarios for sensitivity analysis for pooled model',format.args = list(scientific = FALSE))
```
```{r, echo=FALSE, out.width="40%", out.height="20%", fig.cap="Sensitivity analysis for the pooled model", fig.show='hold', fig.align='center'}
knitr::include_graphics(c('./images/SA_pooled_creatinine.png','./images/SA_pooled_LYVE1.png', './images/SA_pooled_REG1B.png', './images/SA_pooled_TFF1.png'))
``` 


## Hierarchical model

The same way, we created six scenarios for hierarchical model. Scenarios are listed below in the table. The posterior distributions have been plotted so that each scenario has its one color and each diagnosis group different line type. Diagnosis 1 is plotted as dashed line, diagnosis 2 as double dashed line and diagnosis 3 as solid line.

Similarly as in the pooled model, creatinine stays quite same for all the priors but scenarios 5 and 6 are somewhat separate from the others for each diagnosis group. The same kind of behavior can be seen for other proteins as well and even the scenario 6 can be fitted better than in the pooled model. We can conclude that the hierarchical model is not sensitive to the choice of prior parameters since only the unrealistically large changes can be seen in the resulting posterior distributions.

On the other hand, it is noteworthy to say that even though the results end up to be rather good with strange prior distributions, the fitting of the model does not go as smoothly. There occurs a lot of problems initializing the Metropolis algorithm in scenarios 4, 5 and 6. This slows done the computations and might affect other diagnostics of the model. Therefore it is better to use more realistic priors.

```{r echo = FALSE, results = 'asis'}
library(knitr)
S <- matrix(c(1,1,1,1,1,1,0,20,1,1,
              2,2,2,2,2,2,0,10,2,2,
              0.5,0.5,0.5,0.5,0.5,0.5,0,2,0.5,0.5,
              0.01,0.01,0.01,0.01,0.01,0.01,10,1,0.01,0.01,
              100,100,100,100,100,100,1000,1000,100,100,
              100,0.01,100,0.01,100,0.01,-1000,1,100,0.01), ncol = 10, byrow = T)
df <- data.frame(S)
rownames(df) <- c('Scenario 1','Scenario 2','Scenario 3','Scenario 4','Scenario 5','Scenario 6')
colnames(df) <- c('Shape of alpha_Pk', 'Scale of alpha_Pk','Shape of beta_Pk', 'Scale of beta_Pk',
                  'Mean of mu_P1^j', 'Deviation of mu_P1^j','Shape of mu_P2^j', 'Scale of mu_P2^j',
                  'Shape of sigma_Pk^j', 'Scale of sigma_Pk^j')
kable(df, caption='Scenarios for sensitivity analysis for pooled model',format.args = list(scientific = FALSE))
```
```{r, echo=FALSE, out.width="40%", out.height="20%", fig.cap="Sensitivity analysis for the hierarchical model", fig.show='hold', fig.align='center'}
knitr::include_graphics(c('./images/SA_hier_creatinine.png','./images/SA_hier_LYVE1.png', './images/SA_hier_REG1B.png', './images/SA_hier_TFF1.png'))
``` 

# 12 Discussion

- The same issue for REG1B can be seen here as the skewness of the data cannot be taken into account with normal distribution -> skewed distribution on the negative values.

- It is interesting to see that in diagnosis group 1 with healthy control group there is two clear peaks in the data. It would be a good issue to investigate more closely.

- LYVE1 and TFF1 -> It might be a good idea to fit multi-modal distribution instead of normal distribution. But risk for over-fitting, need to find predictors (creatinine) and reasons for multi-modality.

# 13 Conclusion 

# 14 Self-reflection


# References

-   [1] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7031151/
-   [2] Debernardi S, O'Brien H, Algahmdi AS, Malats N, Stewart GD, Plješa-Ercegovac M, et al. (2020) *A combination of urinary biomarker panel and PancRISK score for earlier detection of pancreatic cancer: A case--control study.* PLoS Med 17(12): e1003489. https://doi.org/10.1371/journal.pmed.1003489
